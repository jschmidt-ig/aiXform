# Executive Readout Template

A template for presenting AI pilot outcomes to leadership.

---

## Slide 1: Title

**AI-Accelerated Software Development Pilot**
Executive Readout

[Team Name(s)]
[Date]

---

## Slide 2: Executive Summary

### Headline
[One sentence: What did we accomplish?]

### Key Results
- **[Metric 1]:** [Before] → [After] ([X]% improvement)
- **[Metric 2]:** [Before] → [After] ([X]% improvement)
- **[Metric 3]:** [Before] → [After] ([X]% improvement)

### Recommendation
[One sentence: What should the organization do next?]

---

## Slide 3: What We Did

### Pilot Overview
- **Duration:** 10 weeks (Fundamentals → Labs → Applied)
- **Participants:** [X] team members across [X] teams
- **Focus Areas:** [e.g., Testing, Documentation, Code Quality]

### Approach
1. **Weeks 1-2:** Learned AI fundamentals (concepts, security, best practices)
2. **Weeks 3-6:** Practiced in controlled lab environments
3. **Weeks 7-10:** Applied to real production projects with coaching

---

## Slide 4: Results — Quantitative

### Development Velocity
| Metric | Before | After | Change |
|--------|--------|-------|--------|
| PR cycle time | | | |
| PRs per week | | | |

### Code Quality
| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Test coverage | | | |
| Documentation | | | |

### Time Savings
- Estimated hours saved: [X] hours over pilot period
- Projected annual savings: [X] hours / $[X]

---

## Slide 5: Results — Qualitative

### What Improved
- [Bullet: Specific improvement with example]
- [Bullet: Specific improvement with example]
- [Bullet: Specific improvement with example]

### Team Feedback
> "[Quote from team member about impact]"

> "[Quote from team member about experience]"

### Confidence Scores (1-5 scale)
| Question | Before | After |
|----------|--------|-------|
| "I can effectively use AI in my work" | | |
| "Our team has clear AI practices" | | |

---

## Slide 6: What We Learned

### What Works Well
- [AI is effective for X type of work]
- [Y workflow significantly improved]
- [Z was easier than expected]

### What Requires Caution
- [A requires careful review]
- [B needs human judgment]
- [C doesn't work well with AI]

### Key Success Factors
- [Factor 1: e.g., Clear guidelines]
- [Factor 2: e.g., Team buy-in]
- [Factor 3: e.g., Coaching support]

---

## Slide 7: Team AI Playbook

### We Created Documented Practices For:
- When to use AI (and when not to)
- Data and security rules
- Code review standards for AI-generated code
- Quality gates before merging

### This Enables:
- Consistent practices across the team
- Safe, governed AI usage
- Onboarding for new team members
- Foundation for broader rollout

---

## Slide 8: Capstone Examples

### Example 1: [Title]
- **Task:** [What was done]
- **AI Contribution:** [How AI helped]
- **Result:** [Outcome]
- **Time:** [X hours vs estimated Y hours without AI]

### Example 2: [Title]
- **Task:** [What was done]
- **AI Contribution:** [How AI helped]
- **Result:** [Outcome]
- **Time:** [X hours vs estimated Y hours without AI]

---

## Slide 9: ROI Summary

### Investment
| Item | Cost |
|------|------|
| Training program | $ |
| Time in training | $ |
| Tooling (if any) | $ |
| **Total** | **$** |

### Return
| Item | Value |
|------|-------|
| Time savings | $ |
| Quality improvements | $ |
| **Total** | **$** |

### ROI: [X]%
### Payback Period: [X months]

---

## Slide 10: Recommendations

### Immediate Next Steps
1. [Action 1: e.g., Expand to X additional teams]
2. [Action 2: e.g., Standardize tooling across org]
3. [Action 3: e.g., Create internal champions program]

### Prerequisites for Scaling
- [Tooling/infrastructure needs]
- [Policy/governance updates]
- [Training capacity]

### Suggested Timeline
| Phase | Timeline | Scope |
|-------|----------|-------|
| Pilot complete | Now | [X] teams |
| Wave 2 | [Q] | [X] additional teams |
| Broad rollout | [Q] | Organization-wide |

---

## Slide 11: Risks & Mitigations

### Risks to Monitor
| Risk | Mitigation |
|------|------------|
| Over-reliance on AI | Maintain review discipline, playbook rules |
| Security/data exposure | Clear policies, training, monitoring |
| Quality degradation | Quality gates, metrics tracking |
| Skill atrophy | Balance AI use with manual practice |

### Governance in Place
- Team playbooks document approved practices
- Code review requirements for AI-assisted work
- Security guidelines enforced
- Metrics tracking for continuous monitoring

---

## Slide 12: Questions & Discussion

### Contact
- **Pilot Lead:** [Name, email]
- **Coach:** [Name, email]
- **Sponsor:** [Name, email]

### Resources
- Full ROI report: [link]
- Team playbooks: [link]
- Training materials: [link]

---

## Appendix: Detailed Metrics

[Include detailed data tables, charts, or supporting evidence as needed]

---

## Presentation Tips

### For Presenters
- Lead with the headline result
- Keep slides visual; details in appendix
- Be honest about what didn't work
- Let team members share their own experiences
- Have specific examples ready
- Know your recommendation and be confident in it

### Anticipate Questions
- "How do we know this scales?"
- "What about security risks?"
- "How much will this cost to roll out?"
- "What if people become dependent on AI?"
- "How long until we see ROI?"

### If You Don't Know
- "I don't have that data, but I can follow up"
- "That's a good question for the next phase to explore"
- Never make up numbers
