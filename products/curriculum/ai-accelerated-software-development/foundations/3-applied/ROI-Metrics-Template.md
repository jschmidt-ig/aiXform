# ROI Metrics Template

**Team:** [Team Name]
**Pilot Period:** Weeks 7-10
**Report Date:** [Date]

---

## Executive Summary

[2-3 sentence summary of outcomes. To be completed at end of pilot.]

---

## 1. Baseline Metrics (Week 7)

Capture these metrics BEFORE starting AI-assisted work in Applied phase.

### Development Velocity

| Metric | Baseline Value | Source | Date Captured |
|--------|---------------|--------|---------------|
| Average PR cycle time (open → merge) | | [e.g., GitHub insights] | |
| Average PR size (lines changed) | | | |
| PRs merged per week (team) | | | |
| PRs merged per week (per developer) | | | |

### Code Quality

| Metric | Baseline Value | Source | Date Captured |
|--------|---------------|--------|---------------|
| Test coverage % (overall) | | [e.g., SonarQube] | |
| Test coverage % (focus module) | | | |
| Open bugs (focus area) | | | |
| Technical debt score | | | |

### Documentation

| Metric | Baseline Value | Source | Date Captured |
|--------|---------------|--------|---------------|
| README completeness (1-5 scale) | | Self-assessment | |
| API documentation coverage | | | |
| Runbook exists (Y/N) | | | |

### Time Allocation (Self-Reported)
Estimate how time is currently spent (% of dev time):

| Activity | Baseline % |
|----------|------------|
| Writing new code | |
| Writing tests | |
| Code review | |
| Documentation | |
| Debugging/troubleshooting | |
| Meetings/coordination | |
| Other | |

---

## 2. Progress Tracking (Weeks 8-9)

### AI-Assisted Work Log

| Week | Team Member | Task | AI Tool Used | Time Estimate (without AI) | Actual Time | Notes |
|------|-------------|------|--------------|---------------------------|-------------|-------|
| 8 | | | | | | |
| 8 | | | | | | |
| 9 | | | | | | |
| 9 | | | | | | |

### Weekly Check-In Metrics

**Week 8:**
- PRs completed with AI assistance: ____
- Estimated time saved: ____ hours
- Quality issues found in AI-generated code: ____
- Workflow friction points: [list]

**Week 9:**
- PRs completed with AI assistance: ____
- Estimated time saved: ____ hours
- Quality issues found in AI-generated code: ____
- Workflow friction points: [list]

---

## 3. Final Metrics (Week 10)

### Development Velocity (After)

| Metric | Baseline | Final | Change | % Change |
|--------|----------|-------|--------|----------|
| Average PR cycle time | | | | |
| Average PR size | | | | |
| PRs merged per week (team) | | | | |
| PRs merged per week (per dev) | | | | |

### Code Quality (After)

| Metric | Baseline | Final | Change | % Change |
|--------|----------|-------|--------|----------|
| Test coverage % (overall) | | | | |
| Test coverage % (focus module) | | | | |
| Open bugs (focus area) | | | | |
| Technical debt score | | | | |

### Documentation (After)

| Metric | Baseline | Final | Change |
|--------|----------|-------|--------|
| README completeness (1-5) | | | |
| API documentation coverage | | | |
| Runbook exists (Y/N) | | | |

### Time Allocation (After)

| Activity | Baseline % | Final % | Change |
|----------|------------|---------|--------|
| Writing new code | | | |
| Writing tests | | | |
| Code review | | | |
| Documentation | | | |
| Debugging/troubleshooting | | | |
| Meetings/coordination | | | |
| Other | | | |

---

## 4. Qualitative Assessment

### Team Confidence Survey (1-5 scale)

| Question | Week 7 | Week 10 | Change |
|----------|--------|---------|--------|
| "I understand when to use AI in my work" | | | |
| "I can effectively review AI-generated code" | | | |
| "AI tools improve my productivity" | | | |
| "I trust the quality of AI-assisted output" | | | |
| "Our team has clear practices for AI use" | | | |

### Open Feedback

**What worked well:**
- [Bullet points from team]

**What didn't work:**
- [Bullet points from team]

**Recommendations for broader rollout:**
- [Bullet points from team]

---

## 5. ROI Calculation

### Time Savings

| Category | Hours Saved (4 weeks) | Hourly Rate | Value |
|----------|----------------------|-------------|-------|
| Test writing | | $ | $ |
| Documentation | | $ | $ |
| Code review efficiency | | $ | $ |
| Debugging/troubleshooting | | $ | $ |
| **Total Time Savings** | | | **$** |

### Quality Improvements

| Improvement | Estimated Value | Notes |
|-------------|-----------------|-------|
| Reduced bugs (fewer production issues) | $ | |
| Better documentation (faster onboarding) | $ | |
| Higher test coverage (fewer regressions) | $ | |
| **Total Quality Value** | **$** | |

### Investment

| Cost | Amount |
|------|--------|
| Training program (pilot) | $ |
| Tool licenses (if applicable) | $ |
| Time spent in training | $ |
| **Total Investment** | **$** |

### ROI Summary

```
ROI = (Total Value - Total Investment) / Total Investment × 100

Total Value:      $________
Total Investment: $________
Net Value:        $________
ROI:              ________%
```

---

## 6. Recommendations

### For This Team
- [Continue/expand/modify practices]
- [Specific next steps]

### For Broader Organization
- [Recommendations for rollout to other teams]
- [Suggested pilot criteria]
- [Infrastructure/tooling needs]

### Success Factors
- [What made this pilot successful]
- [Prerequisites for other teams]

### Risk Factors
- [What to watch out for]
- [Common pitfalls]

---

## Appendix: Capstone PRs

List the significant PRs completed during Applied phase:

| PR | Description | AI Assistance | Outcome |
|----|-------------|---------------|---------|
| [link] | | | |
| [link] | | | |
| [link] | | | |

---

## Sign-Off

| Role | Name | Date |
|------|------|------|
| Team Lead | | |
| Coach | | |
| Sponsor | | |
